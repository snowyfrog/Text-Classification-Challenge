{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_input = pd.DataFrame(pd.read_csv(filepath_or_buffer=\"C:/Users/Winte/Downloads/Test_for_the_seminar_apply/Book2.csv\", encoding=\"ms932\", sep=\",\"))\n",
    "#print(csv_input) non dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Winte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Winte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(csv_input, random_state = 9999 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bert = pd.DataFrame({\n",
    "    'id':range(len(train_df)),\n",
    "    'label':train_df[\"Recommended IND\"],\n",
    "    'alpha':['a']*train_df.shape[0],\n",
    "    'text': train_df[\"Review Text\"]})\n",
    "\n",
    "train_df_bert.head()\n",
    "\n",
    "test_df_bert = pd.DataFrame({\n",
    "    'id':range(len(test_df)),\n",
    "    'label':test_df[\"Recommended IND\"],\n",
    "    'alpha':['a']*test_df.shape[0],\n",
    "    'text': test_df[\"Review Text\"]})\n",
    "\n",
    "#test_df_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bert.to_csv('Bert/data/train.tsv', sep='\\t', index=False, header=False)\n",
    "test_df_bert.to_csv('Bert/data/dev.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review Text\n",
      "0  Absolutely wonderful - silky and sexy and comf...\n",
      "1  Love this dress! it sooo pretty. i happened to...\n",
      "2  I had such high hopes for this dress and reall...\n",
      "3  I love, love, love this jumpsuit. it fun, flir...\n",
      "4  This shirt is very flattering to all due to th...\n",
      "5  I love tracy reese dresses, but this one is no...\n",
      "6  I aded this in my basket at hte last mintue to...\n",
      "7  I ordered this in carbon for store pick up, an...\n",
      "8  I love this dress. i usually get an xs but it ...\n",
      "9  I'm 5\"5' and 125 lbs. i ordered the s petite t...\n"
     ]
    }
   ],
   "source": [
    "df_t = pd.DataFrame(csv_input['Review Text'])\n",
    "df_ind = pd.DataFrame(csv_input['Recommended IND'])\n",
    "#print(df_t.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations\n",
    "string.punctuation=('!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "df_t[\"Review Text\"] = df_t[\"Review Text\"].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "#df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review Text\n",
      "0  [absolutely, wonderful, silky, and, sexy, and,...\n",
      "1  [love, this, dress, it, sooo, pretty, i, happe...\n",
      "2  [i, had, such, high, hopes, for, this, dress, ...\n",
      "3  [i, love, love, love, this, jumpsuit, it, fun,...\n",
      "4  [this, shirt, is, very, flattering, to, all, d...\n",
      "5  [i, love, tracy, reese, dresses, but, this, on...\n",
      "6  [i, aded, this, in, my, basket, at, hte, last,...\n",
      "7  [i, ordered, this, in, carbon, for, store, pic...\n",
      "8  [i, love, this, dress, i, usually, get, an, xs...\n",
      "9  [i, m, 55, and, 125, lbs, i, ordered, the, s, ...\n"
     ]
    }
   ],
   "source": [
    "#TOKENIZING\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+')\n",
    "df_t[\"Review Text\"] = df_t[\"Review Text\"].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "print(df_t.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[absolutely, wonderful, silky, and, sexy, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[love, this, dress, it, sooo, pretty, i, happe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, have, such, high, hope, for, this, dress, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, love, love, love, this, jumpsuit, it, fun,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[this, shirt, be, very, flatter, to, all, due,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[i, love, tracy, reese, dress, but, this, one,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[i, aded, this, in, my, basket, at, hte, last,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[i, order, this, in, carbon, for, store, pick,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[i, love, this, dress, i, usually, get, an, x,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[i, m, 55, and, 125, lb, i, order, the, s, pet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text\n",
       "0  [absolutely, wonderful, silky, and, sexy, and,...\n",
       "1  [love, this, dress, it, sooo, pretty, i, happe...\n",
       "2  [i, have, such, high, hope, for, this, dress, ...\n",
       "3  [i, love, love, love, this, jumpsuit, it, fun,...\n",
       "4  [this, shirt, be, very, flatter, to, all, due,...\n",
       "5  [i, love, tracy, reese, dress, but, this, one,...\n",
       "6  [i, aded, this, in, my, basket, at, hte, last,...\n",
       "7  [i, order, this, in, carbon, for, store, pick,...\n",
       "8  [i, love, this, dress, i, usually, get, an, x,...\n",
       "9  [i, m, 55, and, 125, lb, i, order, the, s, pet..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df_t[\"Review Text\"] = df_t[\"Review Text\"].apply(lambda x: \n",
    "                                                [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in x])\n",
    "\n",
    "df_t.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Winte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review Text  Recommended IND\n",
      "0  [absolutely, wonderful, silky, sexy, comfortable]                1\n",
      "1  [love, dress, sooo, pretty, happen, find, stor...                1\n",
      "2  [high, hope, dress, really, want, work, initia...                0\n",
      "3  [love, love, love, jumpsuit, fun, flirty, fabu...                1\n",
      "4  [shirt, flatter, due, adjustable, front, tie, ...                1\n"
     ]
    }
   ],
   "source": [
    "#REMOVE STOPWORDS\n",
    "##IF SUCCESSED CHANGED ALL DF NAME BELOW\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words= stopwords.words(\"english\")\n",
    "\n",
    "stop_words = [x for x in stop_words if x not in [\"not\",\"no\"]]\n",
    "\n",
    "#print(stop_words)\n",
    "\n",
    "df_t[\"Review Text\"] = df_t[\"Review Text\"].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "df_t[\"Recommended IND\"]  = df_ind\n",
    "print(df_t.head())\n",
    "df_t.to_csv(\"processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_t, random_state = 9999 )\n",
    "\n",
    "train_df.to_csv('data/train.csv', index=False, header=False)\n",
    "test_df.to_csv('data/test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from functools import lru_cache\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = json.load(open('products.json', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate lemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tagger pickle\n",
    "tagger = PerceptronTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup if tag is noun, verb, adverb or an adjective\n",
    "tags = {'N': wn.NOUN, 'V': wn.VERB, 'R': wn.ADV, 'J': wn.ADJ}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memoization of POS tagging and Lemmatizer\n",
    "lemmatize_mem = lru_cache(maxsize=10000)(wnl.lemmatize)\n",
    "tagger_mem = lru_cache(maxsize=10000)(tagger.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tag sentences and lemmatize each word\n",
    "def tokenizer(text):\n",
    "    for token in wordpunct_tokenize(text):\n",
    "        if token not in ENGLISH_STOP_WORDS:\n",
    "            tag = tagger_mem(frozenset({token}))\n",
    "            yield lemmatize_mem(token, tags.get(tag[0][1],  wn.NOUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline definition\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        tokenizer=tokenizer,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=ENGLISH_STOP_WORDS,\n",
    "        sublinear_tf=True,\n",
    "        min_df=0.00009\n",
    "    )),\n",
    "    ('classifier', SGDClassifier(\n",
    "        alpha=1e-4, n_jobs=-1\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate using k-fold\n",
    "y_pred = cross_val_predict(\n",
    "    pipeline, dataset.get('data'),\n",
    "    y=dataset.get('target'),\n",
    "    cv=10, n_jobs=-1, verbose=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precison, recall and f1 scode.\n",
    "cr = classification_report(\n",
    "    dataset.get('target'), y_pred,\n",
    "    target_names=dataset.get('target_names'),\n",
    "    digits=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(dataset.get('target'), y_pred)\n",
    "\n",
    "# Get max length of category names for printing\n",
    "label_length = len(\n",
    "    sorted(dataset['target_names'], key=len, reverse=True)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make shortened labels for plotting\n",
    "short_labels = []\n",
    "for i in dataset['target_names']:\n",
    "    short_labels.append(\n",
    "        ' '.join(map(lambda x: x[:3].strip(), i.split(' > ')))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Classification Report\n",
    "print('{label:>{length}}'.format(\n",
    "    label='Classification Report',\n",
    "    length=label_length\n",
    "), cr, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty printing confusion matrix\n",
    "print('{label:>{length}}\\n'.format(\n",
    "    label='Confusion Matrix',\n",
    "    length=abs(label_length - 50)\n",
    "))\n",
    "for index, val in enumerate(cm):\n",
    "    print(\n",
    "        '{label:>{length}} {prediction}'.format(\n",
    "            length=abs(label_length - 50),\n",
    "            label=short_labels[index],\n",
    "            prediction=''.join(map(lambda x: '{:>5}'.format(x), val))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix in a separate window\n",
    "#\n",
    "# sn.set(font_scale=.7)\n",
    "# sn.heatmap(\n",
    "#     cm,\n",
    "#     cmap=\"YlGnBu\", linewidths=.5, fmt='g',\n",
    "#     vmax=150,\n",
    "#     annot=True, annot_kws={\"size\": 9},\n",
    "#     xticklabels=short_labels,\n",
    "#     yticklabels=short_labels\n",
    "# )\n",
    "#\n",
    "# plt.yticks(rotation=45)\n",
    "# plt.xticks(rotation=45)\n",
    "#\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
